{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ❌ **STOP** ❌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a copy of the notebook submitted for evaluation.\n",
    "\n",
    "In this notebook, I will make the suggested modifications as well as including personal changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📋 **TO-DO** 📋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    " - [ ] **Repo** - remove old JNBs\n",
    " - [ ] **Readme** - remove code\n",
    " - [ ] **.Py** - Make 2 sections: used/unused\n",
    " - [ ] **Functions** - Eval_model - add cross-val score evaluation\n",
    "---\n",
    " - [ ] **Proofread** - MarkDown cells, visualization labels\n",
    " - [X] **Recommendations (@top)** - remove from top; create larger summary @ bottom\n",
    " - [ ] **Data cleaning** - convert years to ints, pref. datetime dtype\n",
    " ---\n",
    " - [ ] **Feat.Eng.** - explain *why* I chose to built the features\n",
    " - [ ] **Multicollinearity** - VIF vs. corrmatrix\n",
    " ---\n",
    " - [ ] **Pipeline** - add StandardScaler for X values\n",
    " - [ ] **Pipeline** - move pipeline higher (handling missing values, etc.)\n",
    " - [ ] **Pipeline** - FunctionTransformer (?)\n",
    " - [ ] **Pipeline** - GridSearchCV\n",
    " - [X] **Pipeline** - SimpleImputer mislabeled as \"mode\" vs. \"\n",
    " mean\"\n",
    " ---\n",
    " - [ ] **Coefficients** - quadrillions?!\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#❌-STOP-❌\" data-toc-modified-id=\"❌-STOP-❌-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>❌ <strong>STOP</strong> ❌</a></span></li><li><span><a href=\"#📋-TO-DO-📋\" data-toc-modified-id=\"📋-TO-DO-📋-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>📋 <strong>TO-DO</strong> 📋</a></span></li><li><span><a href=\"#🏡-(Re)Selling-Seattle:-Determining-House-Sell-Prices-🏡-\" data-toc-modified-id=\"🏡-(Re)Selling-Seattle:-Determining-House-Sell-Prices-🏡--3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>🏡 <strong>(Re)Selling Seattle: Determining House Sell Prices</strong> 🏡 <a name=\"title\"></a></a></span></li><li><span><a href=\"#📋-The-Process\" data-toc-modified-id=\"📋-The-Process-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>📋 <strong>The Process</strong></a></span></li><li><span><a href=\"#📂-Setting-Up-the-Tools-and-Data\" data-toc-modified-id=\"📂-Setting-Up-the-Tools-and-Data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>📂 <strong>Setting Up the Tools and Data</strong></a></span><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Importing-Personal-Functions\" data-toc-modified-id=\"Importing-Personal-Functions-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Importing Personal Functions</a></span></li><li><span><a href=\"#Reading-Data\" data-toc-modified-id=\"Reading-Data-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Reading Data</a></span></li></ul></li><li><span><a href=\"#🔬-Exploring-Fresh-Data\" data-toc-modified-id=\"🔬-Exploring-Fresh-Data-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>🔬 <strong>Exploring Fresh Data</strong></a></span><ul class=\"toc-item\"><li><span><a href=\"#Basic-Overviews\" data-toc-modified-id=\"Basic-Overviews-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Basic Overviews</a></span></li><li><span><a href=\"#Data-Cleaning-and-Processing\" data-toc-modified-id=\"Data-Cleaning-and-Processing-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Data Cleaning and Processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Overview-Summary\" data-toc-modified-id=\"Overview-Summary-6.2.1\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span>Overview Summary</a></span></li></ul></li><li><span><a href=\"#Exploring-Features\" data-toc-modified-id=\"Exploring-Features-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Exploring Features<a name=\"features\"></a></a></span></li></ul></li><li><span><a href=\"#🛠-Feature-Engineering\" data-toc-modified-id=\"🛠-Feature-Engineering-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>🛠 <strong>Feature Engineering</strong></a></span><ul class=\"toc-item\"><li><span><a href=\"#'yrs_old_sold'\" data-toc-modified-id=\"'yrs_old_sold'-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span><code>'yrs_old_sold'</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Determine-'year_sold'\" data-toc-modified-id=\"Determine-'year_sold'-7.1.1\"><span class=\"toc-item-num\">7.1.1&nbsp;&nbsp;</span>Determine <code>'year_sold'</code></a></span></li><li><span><a href=\"#Calculate-'yr_old_sold'\" data-toc-modified-id=\"Calculate-'yr_old_sold'-7.1.2\"><span class=\"toc-item-num\">7.1.2&nbsp;&nbsp;</span>Calculate <code>'yr_old_sold'</code></a></span></li></ul></li><li><span><a href=\"#'was_renovated'\" data-toc-modified-id=\"'was_renovated'-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span><code>'was_renovated'</code></a></span></li><li><span><a href=\"#&quot;yrs_since_reno&quot;\" data-toc-modified-id=\"&quot;yrs_since_reno&quot;-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span><code>\"yrs_since_reno\"</code></a></span></li><li><span><a href=\"#&quot;has_bsmnt&quot;\" data-toc-modified-id=\"&quot;has_bsmnt&quot;-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>\"<code>has_bsmnt</code>\"</a></span></li></ul></li><li><span><a href=\"#❌-Fix\" data-toc-modified-id=\"❌-Fix-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>❌ Fix</a></span></li><li><span><a href=\"#🔗-Correlations\" data-toc-modified-id=\"🔗-Correlations-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>🔗 <strong>Correlations</strong></a></span><ul class=\"toc-item\"><li><span><a href=\"#Determining-Correlations-with-Price\" data-toc-modified-id=\"Determining-Correlations-with-Price-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Determining Correlations with Price</a></span></li><li><span><a href=\"#Determining-Multicollinearity\" data-toc-modified-id=\"Determining-Multicollinearity-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>Determining Multicollinearity</a></span></li></ul></li><li><span><a href=\"#🪓-Performing-Train/Test-Split\" data-toc-modified-id=\"🪓-Performing-Train/Test-Split-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>🪓 <strong>Performing Train/Test Split</strong></a></span></li><li><span><a href=\"#📊-Creating-Baseline-Model\" data-toc-modified-id=\"📊-Creating-Baseline-Model-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>📊 <strong>Creating Baseline Model</strong></a></span></li><li><span><a href=\"#🚿-Developing-Data-Preprocessor\" data-toc-modified-id=\"🚿-Developing-Data-Preprocessor-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>🚿 <strong>Developing Data Preprocessor</strong></a></span><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing-Pipeline-via-ColumnTransformer\" data-toc-modified-id=\"Preprocessing-Pipeline-via-ColumnTransformer-12.1\"><span class=\"toc-item-num\">12.1&nbsp;&nbsp;</span>Preprocessing Pipeline via ColumnTransformer</a></span></li></ul></li><li><span><a href=\"#📊-Statsmodels-Non-Formula-OLS-Model\" data-toc-modified-id=\"📊-Statsmodels-Non-Formula-OLS-Model-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>📊 <strong>Statsmodels Non-Formula OLS Model</strong></a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Interpretation\" data-toc-modified-id=\"Interpretation-13.0.1\"><span class=\"toc-item-num\">13.0.1&nbsp;&nbsp;</span>Interpretation</a></span></li></ul></li><li><span><a href=\"#Visualizing-zipcode-coefficients\" data-toc-modified-id=\"Visualizing-zipcode-coefficients-13.1\"><span class=\"toc-item-num\">13.1&nbsp;&nbsp;</span>Visualizing zipcode coefficients</a></span></li><li><span><a href=\"#Visualizing-all-parameters-besides-zipcodes\" data-toc-modified-id=\"Visualizing-all-parameters-besides-zipcodes-13.2\"><span class=\"toc-item-num\">13.2&nbsp;&nbsp;</span>Visualizing all parameters besides zipcodes</a></span></li><li><span><a href=\"#Interpretation\" data-toc-modified-id=\"Interpretation-13.3\"><span class=\"toc-item-num\">13.3&nbsp;&nbsp;</span>Interpretation</a></span></li></ul></li><li><span><a href=\"#🚿-Instantiating-Pipeline\" data-toc-modified-id=\"🚿-Instantiating-Pipeline-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>🚿 <strong>Instantiating Pipeline</strong></a></span><ul class=\"toc-item\"><li><span><a href=\"#Non-Scaled-Pipeline\" data-toc-modified-id=\"Non-Scaled-Pipeline-14.1\"><span class=\"toc-item-num\">14.1&nbsp;&nbsp;</span>Non-Scaled Pipeline</a></span><ul class=\"toc-item\"><li><span><a href=\"#Interpretation\" data-toc-modified-id=\"Interpretation-14.1.1\"><span class=\"toc-item-num\">14.1.1&nbsp;&nbsp;</span>Interpretation</a></span></li><li><span><a href=\"#Verifying-Linear-Regression-Assumptions\" data-toc-modified-id=\"Verifying-Linear-Regression-Assumptions-14.1.2\"><span class=\"toc-item-num\">14.1.2&nbsp;&nbsp;</span>Verifying Linear Regression Assumptions</a></span></li><li><span><a href=\"#Interpretation\" data-toc-modified-id=\"Interpretation-14.1.3\"><span class=\"toc-item-num\">14.1.3&nbsp;&nbsp;</span>Interpretation</a></span></li><li><span><a href=\"#Non-Scaled-Coefficients-for-Recommendations\" data-toc-modified-id=\"Non-Scaled-Coefficients-for-Recommendations-14.1.4\"><span class=\"toc-item-num\">14.1.4&nbsp;&nbsp;</span>Non-Scaled Coefficients for Recommendations</a></span></li></ul></li><li><span><a href=\"#💡-Recommendations---Non-Scaled\" data-toc-modified-id=\"💡-Recommendations---Non-Scaled-14.2\"><span class=\"toc-item-num\">14.2&nbsp;&nbsp;</span>💡 <strong>Recommendations</strong> - <em>Non-Scaled</em></a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-Visualizations-for-Presentation\" data-toc-modified-id=\"Creating-Visualizations-for-Presentation-14.2.1\"><span class=\"toc-item-num\">14.2.1&nbsp;&nbsp;</span>Creating Visualizations for Presentation</a></span></li><li><span><a href=\"#Visualizing-the-Results\" data-toc-modified-id=\"Visualizing-the-Results-14.2.2\"><span class=\"toc-item-num\">14.2.2&nbsp;&nbsp;</span>Visualizing the Results</a></span></li></ul></li><li><span><a href=\"#Scaled-Pipeline\" data-toc-modified-id=\"Scaled-Pipeline-14.3\"><span class=\"toc-item-num\">14.3&nbsp;&nbsp;</span>Scaled Pipeline</a></span><ul class=\"toc-item\"><li><span><a href=\"#Scaled-Coefficients-for-Recommendations\" data-toc-modified-id=\"Scaled-Coefficients-for-Recommendations-14.3.1\"><span class=\"toc-item-num\">14.3.1&nbsp;&nbsp;</span>Scaled Coefficients for Recommendations</a></span></li></ul></li><li><span><a href=\"#💡-Recommendations---Scaled\" data-toc-modified-id=\"💡-Recommendations---Scaled-14.4\"><span class=\"toc-item-num\">14.4&nbsp;&nbsp;</span>💡 <strong>Recommendations</strong> - <em>Scaled</em></a></span><ul class=\"toc-item\"><li><span><a href=\"#Visualizing-Scaled-Results\" data-toc-modified-id=\"Visualizing-Scaled-Results-14.4.1\"><span class=\"toc-item-num\">14.4.1&nbsp;&nbsp;</span>Visualizing Scaled Results</a></span></li></ul></li></ul></li><li><span><a href=\"#💡-Final-Recommendations-💡\" data-toc-modified-id=\"💡-Final-Recommendations-💡-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>💡 <strong>Final Recommendations</strong> 💡</a></span></li><li><span><a href=\"#🔮-Creating-Predictions-on-Holdout-Data\" data-toc-modified-id=\"🔮-Creating-Predictions-on-Holdout-Data-16\"><span class=\"toc-item-num\">16&nbsp;&nbsp;</span>🔮 <strong>Creating Predictions on Holdout Data</strong></a></span></li><li><span><a href=\"#🛠-Processing-New-Data\" data-toc-modified-id=\"🛠-Processing-New-Data-17\"><span class=\"toc-item-num\">17&nbsp;&nbsp;</span><strong>🛠 Processing New Data</strong></a></span><ul class=\"toc-item\"><li><span><a href=\"#'yrs_old_sold'\" data-toc-modified-id=\"'yrs_old_sold'-17.1\"><span class=\"toc-item-num\">17.1&nbsp;&nbsp;</span><code>'yrs_old_sold'</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Determine-'year_sold'\" data-toc-modified-id=\"Determine-'year_sold'-17.1.1\"><span class=\"toc-item-num\">17.1.1&nbsp;&nbsp;</span>Determine <code>'year_sold'</code></a></span></li><li><span><a href=\"#Calculate-'yr_old_sold'\" data-toc-modified-id=\"Calculate-'yr_old_sold'-17.1.2\"><span class=\"toc-item-num\">17.1.2&nbsp;&nbsp;</span>Calculate <code>'yr_old_sold'</code></a></span></li></ul></li><li><span><a href=\"#'was_renovated'\" data-toc-modified-id=\"'was_renovated'-17.2\"><span class=\"toc-item-num\">17.2&nbsp;&nbsp;</span><code>'was_renovated'</code></a></span></li><li><span><a href=\"#&quot;yrs_since_reno&quot;\" data-toc-modified-id=\"&quot;yrs_since_reno&quot;-17.3\"><span class=\"toc-item-num\">17.3&nbsp;&nbsp;</span><code>\"yrs_since_reno\"</code></a></span></li><li><span><a href=\"#&quot;has_bsmnt&quot;\" data-toc-modified-id=\"&quot;has_bsmnt&quot;-17.4\"><span class=\"toc-item-num\">17.4&nbsp;&nbsp;</span>\"<code>has_bsmnt</code>\"</a></span></li><li><span><a href=\"#Dropping-for-Multicollinearity\" data-toc-modified-id=\"Dropping-for-Multicollinearity-17.5\"><span class=\"toc-item-num\">17.5&nbsp;&nbsp;</span>Dropping for Multicollinearity</a></span></li></ul></li><li><span><a href=\"#🔮-Generating-Predictions\" data-toc-modified-id=\"🔮-Generating-Predictions-18\"><span class=\"toc-item-num\">18&nbsp;&nbsp;</span>🔮 <strong>Generating Predictions</strong></a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zh5kWAlsq1k"
   },
   "source": [
    "# 🏡 **(Re)Selling Seattle: Determining House Sell Prices** 🏡 <a name=\"title\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76jtLj8Gsq1n"
   },
   "source": [
    "<a name='bizund'></a>\n",
    "\n",
    "**<p style=\"text-align: center;\">If you are considering selling your house, one of the highest priorities is getting the best price for it.</p>**\n",
    "\n",
    "You want to make sure that the hedges are trimmed; that the basement isn't leaking; and that new coat of paint is covering up all of the \"art\" covering the walls from your kids.\n",
    "\n",
    "*But what else can do you?* Would that extra bathroom under the stairs be a worthwhile addition? What about that addition you always talked about building?\n",
    "\n",
    "---\n",
    "**<p style=\"text-align: center;\">When you are exploring the option of selling, you may ask such questions as:</p>**\n",
    "\n",
    ">* How do the different aspects of your house impact the price?\n",
    ">\n",
    ">\n",
    ">* What can you do to improve the house's value?\n",
    "\n",
    "\n",
    "---\n",
    "You may have some ideas already (and if you don't, watch a few episodes of \"This Old House\" and you will have *plenty* of inspiration).\n",
    "\n",
    "But how do you *really* know what features are best? How can you be sure that your intuition or expectations are based on fact and not assumptions? **Turn to the data for answers!**\n",
    "\n",
    "---\n",
    "**<p style=\"text-align: center;\">Revisiting King County</p>**\n",
    "\n",
    "My [prior exploration](https://github.com/BenJMcCarty/Phase_2_Project_Final) of the King County House Sales dataset yielded some recommendations, but I wanted to see if I can improve them. I am revisiting the data with new techniques and approaches to see how much I can improve the results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📋 **The Process**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76jtLj8Gsq1n"
   },
   "source": [
    "---\n",
    "**<p style=\"text-align: center;\">This project uses data from house sales in King County, WA. to determine the impact of different features on determining the sell price of a home.</p>**\n",
    "\n",
    ">* **First, I explored the data using Pandas.** I reviewed the different features included in my dataset and their respective values; the descriptive statistics for the numerical data; and the overall size and shape of the data (how many rows and columns).\n",
    "\n",
    "\n",
    ">* **Then, I used Seaborn to plot the data and a fitted linear regression model for each feature against the sell price.** These visualizations helped differentiate which features to treat as *categorical* variables (e.g. features that would be one of a select number of options) versus *continuous* variables (which would have a range of values).\n",
    "\n",
    "\n",
    ">* **In order to give more depth to my data, I engineered six new features based on the original features and data.** I determined the age of each house at sale; whether or not a home was renovated; how many years since a renovation; and whether or not a house had a basement.\n",
    "\n",
    "\n",
    ">* **I wanted to make sure all of the features and their data were relevant to apply to my future model.** I performed correlational comparisons to determine which features were too closely related (indicating multicollinearity), which would affect my modeling process later on.\n",
    "\n",
    "\n",
    ">**Once my data was cleaned and prepared, I started the modeling process.**\n",
    ">\n",
    ">\n",
    ">  * I started off with a baseline model created using the average price. It provided me with the baseline RMSE with which I could compare additional models.\n",
    ">\n",
    ">\n",
    ">  * For further processing, I created a simple ColumnTransformer to process missing values and to perform encoding of my categorical variables for modeling.\n",
    ">\n",
    ">\n",
    ">  * Next, I created a Statsmodels version of a linear regression model. I am most familiar with this method of creating linear regression models and used it to generate an $r^2$ value against which to compare my next models.\n",
    ">\n",
    ">\n",
    ">  * I fully crafted my pipeline by combining my preprocessor transformer and a linear regression model class from the Scikit-Learn package. Using this pipeline was a new approach for me, and so I kept it simple and didn't add additional processing before the model.\n",
    ">\n",
    ">\n",
    ">  * For comparison purposes, I created a second pipeline containing a scaler for my input data. The scaling did not impact my $r^2$ or RMSE, but it did shuffle around the rankings for my top positive coefficients for determining price. In the end, though, I felt the data was too hard to explain to my homeowners. I decided to use my non-scaled data for my presentation and recommendations.\n",
    "\n",
    "> **After creating my model, I generated predictions for new housing data.** For my predictions, I performed the same transformations to my data as before, minus the train/test split. After transforming the data, I utilized my trained pipeline to produce my final predictions for submission.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQQLR7ANsq1o"
   },
   "source": [
    "# 📂 **Setting Up the Tools and Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bl8Y9RaXsq1o"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:30.057310Z",
     "start_time": "2021-07-22T02:07:27.168362Z"
    },
    "id": "fwxtrzBMsq1p"
   },
   "outputs": [],
   "source": [
    "# Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Modeling - Statsmodels\n",
    "import statsmodels.api as sms\n",
    "\n",
    "# Modeling - SKLearn\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn import set_config\n",
    "\n",
    "# Settings\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-talk')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.2f}')\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Personal Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created several functions specific to this project and saved them in an external file. The file is available from the main directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:30.214314Z",
     "start_time": "2021-07-22T02:07:30.059311Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# from p2pr_functions.functions import *\n",
    "import p2pr_functions.functions as pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:30.356319Z",
     "start_time": "2021-07-22T02:07:30.218315Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Uncomment cell to review contents of module\n",
    "# help(pf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6WjRioGsq12"
   },
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:30.608310Z",
     "start_time": "2021-07-22T02:07:30.360315Z"
    },
    "id": "O0NN2C4ysq12"
   },
   "outputs": [],
   "source": [
    "## Reading in data as DataFrame\n",
    "xtrain = 'bakeoff_data/Xtrain.csv'\n",
    "ytrain = 'bakeoff_data/ytrain.csv'\n",
    "\n",
    "df_xtrain = pd.read_csv(xtrain)\n",
    "df_ytrain = pd.read_csv(ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nd8bcFoVsq12"
   },
   "source": [
    "# 🔬 **Exploring Fresh Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABcBsWZusq12"
   },
   "source": [
    "## Basic Overviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KViKvrsBsq12"
   },
   "source": [
    "The goal for this section is to get a broad idea of the data before I start any cleaning or feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:30.779311Z",
     "start_time": "2021-07-22T02:07:30.610311Z"
    }
   },
   "outputs": [],
   "source": [
    "df_xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:30.903311Z",
     "start_time": "2021-07-22T02:07:30.782312Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:31.028315Z",
     "start_time": "2021-07-22T02:07:30.906312Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_xtrain, df_ytrain], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:31.166311Z",
     "start_time": "2021-07-22T02:07:31.033312Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:31.384323Z",
     "start_time": "2021-07-22T02:07:31.169324Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "9KY_8DSasq13",
    "outputId": "c14f735d-e743-4955-f104-ae82bd334268",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Review summary of dataframe details\n",
    "pf.report_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOmmqD7koDQi"
   },
   "source": [
    "## Data Cleaning and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:31.572309Z",
     "start_time": "2021-07-22T02:07:31.386311Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NK_VFrBh6-Q1",
    "outputId": "5cfa8293-6e19-435c-ddf8-84aa3ca622d7"
   },
   "outputs": [],
   "source": [
    "## Converting 'date' column to datetime\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:31.700319Z",
     "start_time": "2021-07-22T02:07:31.574327Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dBgOkFsVChMH",
    "outputId": "966e713c-4e28-44ee-bbab-129181812a3d"
   },
   "outputs": [],
   "source": [
    "## Converting 'sqft_basement' to numeric and filling any null values with zero\n",
    "\n",
    "df['sqft_basement'] = pd.to_numeric(df['sqft_basement'], errors='coerce')\n",
    "df['sqft_basement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:31.826314Z",
     "start_time": "2021-07-22T02:07:31.702323Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:31.952356Z",
     "start_time": "2021-07-22T02:07:31.829315Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nRe-PxjkAlUj",
    "outputId": "436d4e4e-f2b3-44db-a970-0d9b9fd2a986"
   },
   "outputs": [],
   "source": [
    "##Filling null values with the most frequent value\n",
    "\n",
    "for col in df:\n",
    "    if df[col].isna().sum() > 0:\n",
    "        df[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:32.189311Z",
     "start_time": "2021-07-22T02:07:31.955313Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Alb_l0T3Bhha",
    "outputId": "39f6a342-034b-4756-835a-bb262c119940"
   },
   "outputs": [],
   "source": [
    "## Reviewing dataframe post-fill\n",
    "\n",
    "pf.report_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxVD4Vyosq14"
   },
   "source": [
    "### Overview Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFgxYi-Ysq14"
   },
   "source": [
    "The dataset contains 20 columns of data, most of which seem useful for evaluations and modeling.\n",
    "\n",
    "I manually fixed null values at this stage - I will start the pipeline later on.\n",
    "\n",
    "After processing, I do not have any null values and all of the datatypes are correct (I can convert some columns into the \"category\" datatype for analysis later, if needed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yr_BhpeHsq14"
   },
   "source": [
    "## Exploring Features<a name='features'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMn26MgRsq14"
   },
   "source": [
    "Now I will be comparing each individual feature against \"price\" to determine if a feature is continuous or categorical.\n",
    "\n",
    "I will check the regressions and histograms for each feature; if a regression plot shows a flatter regression line or if the histogram is not a normal distribution, I will treat that feature as a categorical feature.\n",
    "\n",
    "As part of the function to create the plots, I include my function to ignore any outliers for the purpose of the visualizations. I will *not* change the data itself, though.\n",
    "\n",
    "***Tip:*** *Links are included below for quick navigation to the different features.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='features'></a>\n",
    "\n",
    "| Feature Names | Feature Names  |\n",
    "| ------------ | ------------- |\n",
    "| [Bedrooms](#bedrooms)     | [Sqft_above](#above)    |\n",
    "| [Bathrooms](#bathrooms)    | [Sqft_basement](#base) |\n",
    "| [Sqft_living](#living)  | [Yr_built](#built)      |\n",
    "| [Sqft_lot](#lot)     | [Yr_renovated](#reno)  |\n",
    "| [Floors](#floors)       | [Zipcode](#zip)       |\n",
    "| [Waterfront](#wf)   | [Lat](#lat)           |\n",
    "| [View](#view)         | [Long](#long)          |\n",
    "| [Condition](#cond)    | [Sqft_living15](#living15)    |\n",
    "| [Grade](#grade)        | [Sqft_lot15](#lot15)    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esH0MiIUsq14"
   },
   "source": [
    "**Bedrooms** <a name=\"bedrooms\"></a> [🔝](#features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:33.770313Z",
     "start_time": "2021-07-22T02:07:32.191311Z"
    },
    "id": "71XLgj2isq15",
    "outputId": "935aaf0c-4523-4be1-e154-f9af9653bf40"
   },
   "outputs": [],
   "source": [
    "pf.show_cleaned_vis(data=df,x='bedrooms', categorical=True, kde = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIKLDVvVsq15"
   },
   "source": [
    "***\n",
    "**Observations**\n",
    ">* There is a slight linear regression between the number of bedrooms and the sell price, indicated by the positive slope of the regression line.\n",
    ">\n",
    ">\n",
    ">* The histogram slightly resembles a normal distribution, although the first and last bins are lower than I would expect for a normal distribution.\n",
    "\n",
    "***\n",
    "**TO-DO**\n",
    ">* Use `'bedrooms'` as a categorical variable.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PoQcwoMsq15"
   },
   "source": [
    "**Bathrooms** <a name=\"bathrooms\"></a> [🔝](#features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:35.150310Z",
     "start_time": "2021-07-22T02:07:33.773312Z"
    },
    "id": "uTpdKmEQsq15",
    "outputId": "929c2b48-248b-4065-9153-364279aa73ac",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pf.show_cleaned_vis(df,\"bathrooms\", categorical=True, kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JqSGJlJXsq15"
   },
   "source": [
    "***\n",
    "**Observations**\n",
    ">* There is a clear linear relationship between bathrooms and price.\n",
    ">\n",
    ">\n",
    ">* The histogram/normal distribution isn't the strongest, particularly for the larger number of bathrooms.\n",
    "\n",
    "***\n",
    "**TO-DO**\n",
    ">\n",
    ">* Similar to bedrooms, the values for number of bathrooms are discrete and fall into specific values. This indicates that the feature is categorical.\n",
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhXyxOvesq15"
   },
   "source": [
    "**Sqft_living** <a name=\"living\"></a> [🔝](#features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:36.759312Z",
     "start_time": "2021-07-22T02:07:35.153311Z"
    },
    "id": "_2Cv_c8gsq16",
    "outputId": "ae5b0f3d-632a-46de-c90d-9bafc61a53e9"
   },
   "outputs": [],
   "source": [
    "pf.show_cleaned_vis(df,\"sqft_living\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCamjs1Csq17"
   },
   "source": [
    "***\n",
    "**Observations**\n",
    "\n",
    ">* There is a clear linear relationship, although the distribution is slightly skewed to the right, indicating it's not a perfect normal distribution.\n",
    ">\n",
    ">\n",
    ">* As the values are spread across the whole range, this feature is clearly a continuous variable.\n",
    "\n",
    "***\n",
    "\n",
    "**To-Do**\n",
    "\n",
    ">* Use as continuous variable\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSq414W9sq17"
   },
   "source": [
    "**Sqft_lot** <a name=\"lot\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:38.196345Z",
     "start_time": "2021-07-22T02:07:36.762313Z"
    },
    "id": "mt-YYo6Gsq17",
    "outputId": "c1ebdfcd-0cb6-452b-f3f2-3741dc4883d0"
   },
   "outputs": [],
   "source": [
    "pf.show_cleaned_vis(df,\"sqft_lot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ckn113g_sq17"
   },
   "source": [
    "***\n",
    "**Observations**\n",
    "\n",
    ">* Weak linear relationship with price; distribution skewed right.\n",
    "***\n",
    "\n",
    "**To-Do**\n",
    "\n",
    ">* Treat as continuous variable as the values are spread out across the whole range.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJN32UMQsq18"
   },
   "source": [
    "**Floors** <a name=\"floors\"></a> [🔝](#features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:39.642340Z",
     "start_time": "2021-07-22T02:07:38.198349Z"
    },
    "id": "SX_3n2SHsq18",
    "outputId": "016730e9-f040-44df-b385-27583b677b6b"
   },
   "outputs": [],
   "source": [
    "pf.show_cleaned_vis(df,\"floors\", kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1uS1Lb5tsq18"
   },
   "source": [
    "***\n",
    "**Observations**\n",
    "\n",
    ">* Linear relationship, but clearly categorical as the values fall into specific categories ranging from 1-3.5\n",
    ">\n",
    ">* Most homes had one or two floors.\n",
    "\n",
    "***\n",
    "**To-Do**\n",
    "\n",
    ">* Treat as categorical variable.\n",
    " \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKYMc5wOsq19"
   },
   "source": [
    "**Waterfront** <a name=\"wf\"></a> [🔝](#features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:41.048345Z",
     "start_time": "2021-07-22T02:07:39.645315Z"
    },
    "id": "YcdNRh3Csq19",
    "outputId": "58a2e2e3-e332-4e6c-b49e-39ccedd63c4e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pf.feature_vis(df,\"waterfront\", categorical=True, kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEdL6h4nsq19"
   },
   "source": [
    "***\n",
    "**Observations**\n",
    "\n",
    ">* Graphs are misleading - clearly binary variable with a slight linear relationship.\n",
    ">\n",
    ">\n",
    ">* Most properties are non-waterfront.\n",
    ">\n",
    ">\n",
    ">* Clear linear relationship, but not normally distributed\n",
    "\n",
    "***\n",
    "**To-Do**\n",
    "\n",
    ">* Treat as categorical - only two options (0 or 1).\n",
    " \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCVzAq8esq19"
   },
   "source": [
    "**View** <a name=\"view\"></a> [🔝](#features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:42.422311Z",
     "start_time": "2021-07-22T02:07:41.050311Z"
    },
    "id": "8iQdM8agsq19",
    "outputId": "ca94d504-1046-4a59-ce71-90fded2be326",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pf.feature_vis(df,\"view\", categorical=True, kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dz1VgSkvsq1-"
   },
   "source": [
    "***\n",
    "**Observations**\n",
    "\n",
    ">* Slight linear relationship - higher \"view\" rating, higher price\n",
    ">\n",
    ">\n",
    ">* Most homes have '0' view\n",
    ">\n",
    ">\n",
    ">* A few extreme outliers in pricing (for values 2, 3, and 4s)\n",
    "\n",
    "***\n",
    "**To-Do**\n",
    "\n",
    ">* Treat as categorical\n",
    " \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFK6Oe3Nsq1-"
   },
   "source": [
    "**Condition** <a name=\"cond\"></a> [🔝](#features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:43.935311Z",
     "start_time": "2021-07-22T02:07:42.424313Z"
    },
    "id": "MfMn5q0esq1-",
    "outputId": "4f558c05-ac1f-4ee1-eaa9-739d6242757a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pf.show_cleaned_vis(df,\"condition\", categorical=True, kde= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgI1_0Umsq1-"
   },
   "source": [
    "***\n",
    "**Observations**\n",
    "\n",
    ">* Largest number of homes sold were in condition 3, followed by condition 4.\n",
    ">\n",
    ">\n",
    ">* Very few homes sold with conditions of 1s or 2s.\n",
    ">\n",
    ">\n",
    ">* Price outliers in 4.0 area, some slight outliers in 2 and 3\n",
    ">\n",
    ">\n",
    ">* No linear relationship, not normal distribution.\n",
    "\n",
    "***\n",
    "**TO-DO**\n",
    "\n",
    ">* Treat as categorical\n",
    " \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShUVl0iisq1_"
   },
   "source": [
    "**Grade** <a name=\"grade\"></a> [🔝](#features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:45.366310Z",
     "start_time": "2021-07-22T02:07:43.940312Z"
    },
    "id": "RfuwzUUfsq1_",
    "outputId": "e71c43ff-9fc2-4dad-9ae3-ccd7e3c4ad34",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pf.show_cleaned_vis(df,\"grade\", kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LA6v2PInsq1_"
   },
   "source": [
    "**Observations**\n",
    "\n",
    ">* Clear linear trend - as grade increases, so does price\n",
    ">\n",
    ">\n",
    ">* Grades range from 6-9\n",
    ">\n",
    ">\n",
    ">* Price outliers for grades 7 and 8\n",
    "\n",
    "---\n",
    "**To-Do**\n",
    "\n",
    ">* Treat as categorical variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RR77jhqZsq2A"
   },
   "source": [
    "**Sqft_above** <a name=\"above\"></a> [🔝](#features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:46.911312Z",
     "start_time": "2021-07-22T02:07:45.369312Z"
    },
    "id": "DHsYgwg8sq2A",
    "outputId": "795cfa4e-6c86-44a2-e12e-24b373d1d9de",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pf.show_cleaned_vis(df,\"sqft_above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ceio_9Hxsq2A"
   },
   "source": [
    "---\n",
    "\n",
    "**Observations**\n",
    "\n",
    ">* Outliers impacting accuracy of linear regression, but still seems relatively linear.\n",
    ">\n",
    ">\n",
    ">* Distribution skewed right, but otherwise normal\n",
    "---\n",
    "**TO-DO**\n",
    "\n",
    ">* Treat as continuous\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mV_Ai-awsq2B"
   },
   "source": [
    "**Sqft_basement** <a name=\"base\"></a>[🔝](#features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:48.430360Z",
     "start_time": "2021-07-22T02:07:46.914312Z"
    },
    "id": "AdhxJs8Dsq2B",
    "outputId": "65dc3e4a-deec-46e9-e0f8-63d9a5eb2a0b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pf.show_cleaned_vis(df,\"sqft_basement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtQWfKTNsq2B"
   },
   "source": [
    "---\n",
    "**Observations**\n",
    "\n",
    ">* There is a very large number of 0 ft$^2$ basements, indicating that these homes do not have a basement\n",
    ">\n",
    ">\n",
    ">* There are scattered outliers in pricing\n",
    ">\n",
    ">\n",
    ">* The regression is poor due to the large number of 0 values\n",
    "\n",
    "---\n",
    "**To-Do**\n",
    "\n",
    ">* Treat as a continuous variable\n",
    ">\n",
    ">\n",
    ">* Can create new categorical, binary variable to indicate whether or not a house has a basement to measure the impact on price.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rFbdTozsq2B"
   },
   "source": [
    "**Yr_built** <a name=\"built\"></a> [🔝](#features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:49.959311Z",
     "start_time": "2021-07-22T02:07:48.432316Z"
    },
    "id": "gM1k8hcKsq2C",
    "outputId": "8760fecc-dc75-4bf1-ff0c-33232173dbd7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pf.show_cleaned_vis(df,\"yr_built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dMEm9GJsq2C"
   },
   "source": [
    "---\n",
    "**Observations**\n",
    "\n",
    ">* No linear trend from this regression plot\n",
    ">\n",
    ">* Seems like may houses built between 1940 - 1970, then major boom in early 2000s.\n",
    ">\n",
    ">* Some significant outliers in price, but not enough to  impact the regression\n",
    "---\n",
    "\n",
    "**To-Do**\n",
    "\n",
    ">* Compare year built to year sold - how old was the house at sale?\n",
    ">\n",
    ">\n",
    ">* Potentially discretize for analysis.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSfdRI4Fsq2C"
   },
   "source": [
    "**Yr_renovated** <a name=\"reno\"></a> [🔝](#features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:51.320314Z",
     "start_time": "2021-07-22T02:07:49.961311Z"
    },
    "id": "bzlSV8vTsq2C",
    "outputId": "45c0cf96-4296-45e9-a3ac-3764ec924fd3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pf.feature_vis(df,'yr_renovated', kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oGuuSiZsq2C"
   },
   "source": [
    "---\n",
    "**Observations**\n",
    "\n",
    ">* Number of houses not renovated significantly outweighs the number renovated\n",
    ">\n",
    ">\n",
    ">* Graphs indicate that an engineered feature for whether or not the house was renovated would be worthwhile.\n",
    "\n",
    "---\n",
    "**To-Do**\n",
    "\n",
    ">* Create new categorical feature - renovated or not\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8HlMm5zsq2C"
   },
   "source": [
    "**Zipcode** <a name=\"zip\"></a> [🔝](#features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:53.062310Z",
     "start_time": "2021-07-22T02:07:51.323315Z"
    },
    "id": "QE6O2kLnsq2C",
    "outputId": "3ec0d472-458f-445e-a323-333a62154e85",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pf.show_cleaned_vis(df,\"zipcode\", categorical=True, kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-P7OXcasq2D"
   },
   "source": [
    "---\n",
    "**Observations**\n",
    "\n",
    ">* No linear relationship; not normally distributed\n",
    "---\n",
    "**TO-DO**\n",
    "\n",
    ">* Treat as categorical variable\n",
    ">\n",
    ">* Perform OneHotEncoding to create new features for modeling.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpeCeCCasq2D"
   },
   "source": [
    "**Lat** <a name=\"lat\"></a> [🔝](#features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:54.729345Z",
     "start_time": "2021-07-22T02:07:53.065329Z"
    },
    "id": "Kc4AN0Rrsq2D",
    "outputId": "1fba4c7c-6084-406f-8f1e-5ba58313e1b4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pf.show_cleaned_vis(df,\"lat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFLAb-cQsq2D"
   },
   "source": [
    "---\n",
    "**Observations**\n",
    "\n",
    ">* Very weak linear relationship and not normally distributed.\n",
    ">\n",
    ">\n",
    ">* Outliers just slightly past 47.6 degrees latitude\n",
    "\n",
    "---\n",
    "**To-Do**\n",
    "\n",
    ">* Treat as categorical for modeling.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKBhksmKsq2D"
   },
   "source": [
    "**Long** <a name=\"long\"></a> [🔝](#features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:56.335313Z",
     "start_time": "2021-07-22T02:07:54.731327Z"
    },
    "id": "bE3EPDPMsq2D",
    "outputId": "d707bf01-73d7-4fb7-f531-ddaa8d272aa5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pf.show_cleaned_vis(df,\"long\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kj7xgYRsq2E"
   },
   "source": [
    "---\n",
    "**Observations**\n",
    "\n",
    ">* No linear relationship and not normally distributed.\n",
    ">\n",
    ">\n",
    ">* Outliers around -122.32ish and -122.25-ish degrees\n",
    "\n",
    "---\n",
    "**To-Do**\n",
    "\n",
    ">* Treat as continuous if used for modeling.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDv_3hS5sq2E"
   },
   "source": [
    "**Sqft_living15** <a name=\"living15\"></a> [🔝](#features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:57.865314Z",
     "start_time": "2021-07-22T02:07:56.337313Z"
    },
    "id": "luLGHfCKsq2E",
    "outputId": "fb3be1d6-fd85-4530-94ed-86960a88b312",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pf.show_cleaned_vis(df,\"sqft_living15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtVJ3AkLsq2E"
   },
   "source": [
    "---\n",
    "**Observations**\n",
    "\n",
    ">* Most properties sold between 1500/2000 ft$^2$ living space\n",
    ">\n",
    ">\n",
    ">* Price follows linear trend and is normally distributed, although skewed right.\n",
    ">\n",
    ">* Outliers between 2500-3500 ft$^2$ \n",
    "---\n",
    "**TO-DO**\n",
    "\n",
    ">* Treat as continuous variable\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjQYCqAasq2E"
   },
   "source": [
    "**Sqft_lot15** <a name=\"lot15\"></a> [🔝](#features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:59.359310Z",
     "start_time": "2021-07-22T02:07:57.867313Z"
    },
    "id": "2Wv8CQbrsq2F",
    "outputId": "5dd25e0c-e026-430d-e8c1-7090c01a67a5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pf.show_cleaned_vis(df,\"sqft_lot15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eF1dX4Opsq2F"
   },
   "source": [
    "---\n",
    "**Observations**\n",
    "\n",
    ">* No clear linear trend\n",
    ">* Significant outlier at approx. 9000 ft$^2$\n",
    "\n",
    "---\n",
    "**TO-DO**\n",
    ">* Treat as continuous variable\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0RzFYbgcsq2F"
   },
   "source": [
    "# 🛠 **Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mpimDh2sq2F"
   },
   "source": [
    "## `'yrs_old_sold'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmU0Rwyjsq2F"
   },
   "source": [
    "I create this feature to differentiate between houses that were built recently versus older houses.\n",
    "\n",
    "In order to determine this feature, I need to determine the year the house was sold first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgTdOjJnsq2F"
   },
   "source": [
    "### Determine `'year_sold'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:59.484313Z",
     "start_time": "2021-07-22T02:07:59.361315Z"
    },
    "id": "ltoQKbEFsq2G",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Pull the year from the \"date\" column\n",
    "df['year_sold'] = pd.DatetimeIndex(df['date']).year\n",
    "\n",
    "## Review the values to ensure data integrity\n",
    "df['year_sold'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9dY6ryUsq2G"
   },
   "source": [
    "### Calculate `'yr_old_sold'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:59.625313Z",
     "start_time": "2021-07-22T02:07:59.487313Z"
    },
    "id": "EjI_PHB0sq2G",
    "outputId": "f8199020-11ed-4252-80af-ee86afb89a78",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Calculating the age of the house at the time of sale\n",
    "df['yr_old_sold'] = df['year_sold'] - df['yr_built']\n",
    "\n",
    "## Minimum age is -1 due to a house being sold before it was finished being built\n",
    "display(df['yr_old_sold'].value_counts().sort_index(), df['yr_old_sold'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Results:** Half of the homes sold fall between the ages of 18 and 63 years old, with the average age of 43 years. Our min and max ages indicate a house was sold before it was built, while another house was 115 years old."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gzl5f2Ktsq2H"
   },
   "source": [
    "## `'was_renovated'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vL3j33BYsq2H"
   },
   "source": [
    "What impact would a renovation have on the price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:59.781312Z",
     "start_time": "2021-07-22T02:07:59.628315Z"
    },
    "id": "X7QoQoBLsq2I"
   },
   "outputs": [],
   "source": [
    "## Using the year that the home was renovated to deterine whether or not the home was renovated\n",
    "reno_y_n = np.where(df['yr_renovated']>0, 1, 0 )\n",
    "df = df.assign(was_renovated = reno_y_n)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:07:59.907360Z",
     "start_time": "2021-07-22T02:07:59.783323Z"
    },
    "id": "kltnwNfIsq2I",
    "outputId": "caaada13-58e0-4c08-cf62-7b8fbeedf911"
   },
   "outputs": [],
   "source": [
    "## Checking values\n",
    "df['was_renovated'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Results:** Most of the houses were not renovated at the time of sale. This feature may not have a significant impact on determining the sale price due to the small number of renovated houses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb2ISg5Xsq2I"
   },
   "source": [
    "## `\"yrs_since_reno\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFYYV9xCsq2I"
   },
   "source": [
    "If a house was renovated, how long ago was the renovation? Would more newly-renovated houses increase price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:08:00.062344Z",
     "start_time": "2021-07-22T02:07:59.909311Z"
    }
   },
   "outputs": [],
   "source": [
    "## Ensuring there are no null values in the new feature and replacing any with zeroes\n",
    "\n",
    "df['yrs_since_reno'] = np.where((df['was_renovated']==1),\n",
    "                                (df['year_sold'] - df['yr_renovated']), 0)\n",
    "\n",
    "display(df['yrs_since_reno'].describe(),df['yrs_since_reno'].value_counts(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:08:00.187310Z",
     "start_time": "2021-07-22T02:08:00.065312Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Checking for which properties show a renovation year post-sale\n",
    "\n",
    "df[df['year_sold'] < df['yr_renovated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:08:00.326312Z",
     "start_time": "2021-07-22T02:08:00.189324Z"
    }
   },
   "outputs": [],
   "source": [
    "## Reviewing stats for those houses that were renovated\n",
    "\n",
    "yrs_and_reno = df[df['yrs_since_reno'] > 0]\n",
    "yrs_and_reno['yrs_since_reno'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Results:** As expected, most of the houses were not renovated (indicated by the number of years being zero). \n",
    ">\n",
    ">\n",
    ">Of those renovated, half of the homes had between 9 and 28 years between the years sold and renovated, with an average ages of roughly 20 years old.\n",
    ">\n",
    ">\n",
    ">Interestingly, this dataset also shows *six records for which the renovation is shown to be post-sale.* While this may be an error, I am leaving it in the dataset since I cannot confidently rule it out. \n",
    ">\n",
    ">\n",
    ">If this feature does not show statistical significance, I may drops these values and reevaluate the significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6TwLd00sq2J"
   },
   "source": [
    "## \"`has_bsmnt`\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fl4Yn656sq2J"
   },
   "source": [
    "I noticed that there were fewer houses with a value for \"sqft_basement\" during my data exploration. I am curious if the presence or absence of a basement would have any impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:08:00.576310Z",
     "start_time": "2021-07-22T02:08:00.328311Z"
    },
    "id": "lWHPc64-sq2J",
    "outputId": "1b48b91d-ebaf-4cdb-be5d-811fa8334a21",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Determining whether or not a house has a basement based on the square footage\n",
    "df['has_bsmnt'] = np.where(df['sqft_basement'] > 0, 1, 0)\n",
    "\n",
    "# Reviewing the results\n",
    "display(df['has_bsmnt'].describe(), df['has_bsmnt'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:08:00.702309Z",
     "start_time": "2021-07-22T02:08:00.579312Z"
    }
   },
   "outputs": [],
   "source": [
    "6271/16197"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ❌ Fix\n",
    ">**Results:** Surprisingly, it seems that 38% of homes have basements, which is  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puQqlrLFsq2K"
   },
   "source": [
    "# 🔗 **Correlations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wf4tEuN1sq2K"
   },
   "source": [
    "## Determining Correlations with Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:08:00.825309Z",
     "start_time": "2021-07-22T02:08:00.704311Z"
    },
    "id": "sOw4_jhVsq2K",
    "outputId": "90b78d09-3d7d-4737-c9ca-65c6967ccf66"
   },
   "outputs": [],
   "source": [
    "## Determining top five features most strongly correlated with price\n",
    "## (Considering absolute values for magnitude, not direction)\n",
    "\n",
    "df_corr = np.abs(df.drop(['price', 'lat','long', 'yr_renovated'], axis=1).corrwith(df['price']).sort_values(ascending=False))\n",
    "display(df_corr[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Co8mLW6Zsq2K"
   },
   "source": [
    "## Determining Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:08:04.278349Z",
     "start_time": "2021-07-22T02:08:00.828311Z"
    },
    "id": "6LjFop6Psq2L",
    "outputId": "bf3ad586-7fec-4f97-98a0-cfec0ca1ae72"
   },
   "outputs": [],
   "source": [
    "## Creating correlation matrix w/ heatmap for intensity of values\n",
    "pf.corr_val(df.drop(['price'],axis=1), figsize=(20,20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:08:04.433332Z",
     "start_time": "2021-07-22T02:08:04.281314Z"
    },
    "id": "FZyJieM6sq2L"
   },
   "outputs": [],
   "source": [
    "## Correlation results ignoring duplicate values \n",
    "## Except for \"was_renovated\", which shows a perfect relationship to itself\n",
    "\n",
    "df_corr_results = np.abs(df.drop(['price','yr_renovated'],axis=1).corr().unstack().sort_values(ascending=False).drop_duplicates())\n",
    "\n",
    "## Show strongest correlations\n",
    "df_corr_results[1:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:49:34.296191Z",
     "start_time": "2021-07-14T17:49:34.176157Z"
    }
   },
   "source": [
    "**Results:** From the correlation matrix, I see that we have seven pairs of features that show a correlation over .75.\n",
    "\n",
    "I will drop 'sqft_living', 'was_renovated', and 'has_basement' due to their high correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:08:04.586327Z",
     "start_time": "2021-07-22T02:08:04.435318Z"
    },
    "id": "NX0PsIQmsq2L"
   },
   "outputs": [],
   "source": [
    "# Dropping columns to address multicollinearity (over .75)\n",
    "drop_feats = ['was_renovated', 'sqft_living','has_bsmnt']\n",
    "df_dropped = df.drop(drop_feats, axis=1)\n",
    "# df_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:08:07.200345Z",
     "start_time": "2021-07-22T02:08:04.591324Z"
    },
    "id": "NfHwiihhsq2L",
    "outputId": "ba07fadc-541d-4a1b-f4ab-a0d279166b54"
   },
   "outputs": [],
   "source": [
    "# Rerunning model\n",
    "pf.corr_val(df_dropped.drop('price',axis=1), figsize=(20,20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:08:07.340310Z",
     "start_time": "2021-07-22T02:08:07.203313Z"
    },
    "id": "lz6NhZtDsq2M",
    "outputId": "9ceda911-5bc3-478a-ff30-4653b676a0b5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Correlation results ignoring (most) duplicate values\n",
    "df_corr_results = df_dropped.drop('price',axis=1).corr().unstack().sort_values(ascending=False).drop_duplicates()\n",
    "\n",
    "## Show strongest correlations\n",
    "print(df_corr_results[1:11],'\\n\\n',df_corr_results[-11:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Results:** After dropping the highly-correlated features, all of my feature correlations are below .8, helping to address any multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🪓 **Performing Train/Test Split**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwP6qaTEsq2m"
   },
   "source": [
    "Now I will split the data into the train/test groups. Then, I will run the first linear regression on the \"train\" data, then another regression on the \"test\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:08:07.479310Z",
     "start_time": "2021-07-22T02:08:07.343327Z"
    },
    "id": "OU4PKAM1sq2l"
   },
   "outputs": [],
   "source": [
    "## Creating features matrix minus target variable\n",
    "X = df_dropped.drop('price', axis = 1).copy()#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:08:07.588311Z",
     "start_time": "2021-07-22T02:08:07.481335Z"
    },
    "id": "me9QULf1sq2l"
   },
   "outputs": [],
   "source": [
    "## Creating the y values by setting them equal to the 'price' values from the dataframe\n",
    "y = df_dropped['price'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:08:07.728343Z",
     "start_time": "2021-07-22T02:08:07.590314Z"
    },
    "id": "gdxlPa7fsq2l",
    "outputId": "94e25dd6-f2e6-455e-9e64-0b38ccc9ab09"
   },
   "outputs": [],
   "source": [
    "## Verifying the two groups are of equal length\n",
    "X.shape[0] == y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:08:07.854314Z",
     "start_time": "2021-07-22T02:08:07.731339Z"
    },
    "id": "VfB9_nl0sq2m"
   },
   "outputs": [],
   "source": [
    "## Establishing the train and test sets for modeling\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,\n",
    "                                                    random_state=505)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📊 **Creating Baseline Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:08:08.010347Z",
     "start_time": "2021-07-22T02:08:07.857314Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline = DummyRegressor()\n",
    "\n",
    "baseline.fit(X_train, y_train)\n",
    "print(f'The baseline r^2 score is: {baseline.score(X_train, y_train):.2f}\\n\\n')\n",
    "pf.eval_perf_total(baseline, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Analysis:** The baseline RMSE for the training data shows an error of over 365,000, a substantial amount of error. On the testing data, it seems the model did slightly worse than the training.\n",
    ">\n",
    ">\n",
    ">* My goal is to build a model that performs better than this baseline model in terms of both RMSE and r$^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Do not delete this cell! It has anchors for other links -->\n",
    "\n",
    "<a name=\"eod\"></a>\n",
    "<a name=\"pipeline_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚿 **Developing Data Preprocessor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Pipeline via ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This combination of transformers is designed to handle any missing values by imputing either a '0' or the mean value for the feature. Additionally, this transformer will perform one-hot encoding for my categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:09:45.417345Z",
     "start_time": "2021-07-22T02:09:45.303360Z"
    }
   },
   "outputs": [],
   "source": [
    "## Specifying features for each transformer (below)\n",
    "\n",
    "imp_zero_cols = ['sqft_basement']\n",
    "imp_mean_cols = ['view','waterfront','yr_renovated']\n",
    "ohe_cols = ['condition','grade', 'zipcode']\n",
    "\n",
    "xf_cols = [*imp_zero_cols, *imp_mean_cols, *ohe_cols]\n",
    "\n",
    "remaining_cols = [i for i in X.drop('date', axis=1).columns if i not in xf_cols]\n",
    "\n",
    "imp_zero_cols.extend(remaining_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:09:45.574343Z",
     "start_time": "2021-07-22T02:09:45.420360Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Creating ColumnTransformer and sub-transformers for imputation and encoding\n",
    "\n",
    "# Adding zeroes for missing values in sqft_basement\n",
    "zero_transformer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "\n",
    "## Adding the mode value to view, waterfront, and yr_renovated missing values \n",
    "mean_transformer = SimpleImputer(strategy='mean')\n",
    "\n",
    "## Encoding categoricals - handling errors to prevent issues w/ test set\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "## Instantiating the ColumnTransformer and including all transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('zero', zero_transformer, imp_zero_cols),\n",
    "                  ('mean', mean_transformer, imp_mean_cols),\n",
    "                  ('cats', categorical_transformer, ohe_cols)])\n",
    "\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📊 **Statsmodels Non-Formula OLS Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">I create a Statsmodels version of the regression model to compare against my later SKLearn models. I use this comparison to ensure that the SKLearn pipeline below creates the same predictions for the same transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:15.801228Z",
     "start_time": "2021-07-22T02:10:15.512255Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preprocessor.fit(X_train)\n",
    "\n",
    "## Getting feature names from OHE\n",
    "ohe_cat_names = preprocessor.named_transformers_['cats'].get_feature_names(ohe_cols)\n",
    "\n",
    "## Generating list for column index\n",
    "final_cols = [*imp_zero_cols, *imp_mean_cols, *ohe_cat_names]\n",
    "\n",
    "## Fit and transform the data via the ColumnTransformer\n",
    "X_train_tf = preprocessor.transform(X_train)\n",
    "X_train_tf_df = pd.DataFrame(X_train_tf, columns=final_cols, index=X_train.index)\n",
    "\n",
    "## Transforming the test set and saving\n",
    "X_test_tf = preprocessor.transform(X_test)\n",
    "X_test_tf_df = pd.DataFrame(X_test_tf, columns=final_cols, index=X_test.index)\n",
    "\n",
    "display(X_train_tf_df.head(5),X_test_tf_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:16.161225Z",
     "start_time": "2021-07-22T02:10:15.804227Z"
    }
   },
   "outputs": [],
   "source": [
    "## Running a Statsmodels OLS model for verification\n",
    "sm_reg = sms.OLS(y_train, X_train_tf_df).fit()#sms.add_constant()\n",
    "\n",
    "sm_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:16.304230Z",
     "start_time": "2021-07-22T02:10:16.164227Z"
    }
   },
   "outputs": [],
   "source": [
    "## Pulling SM-OLS coefficients\n",
    "model_params = sm_reg.params\n",
    "model_params.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The r$^2$-score of .84 is good and almost all of my features are statistically-significant (with a p-value of .05, all but 2 exceed the threshold).\n",
    ">\n",
    "> Despite the strong scores, the coefficients are extremely high, raising questions about the quality of the data. As this model is only for comparison purposes, I will move on without digging into the results.\n",
    ">\n",
    "> **Now I will visualize the results to demonstrate the intensity of the results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T01:37:36.972554Z",
     "start_time": "2021-07-15T01:37:34.387537Z"
    }
   },
   "source": [
    "## Visualizing zipcode coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:16.444241Z",
     "start_time": "2021-07-22T02:10:16.306226Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Generating lists of coefficient names for filtering\n",
    "\n",
    "zipcode_cols = [x for x in model_params.index if x.startswith('zipcode')]\n",
    "\n",
    "only_zips = model_params[zipcode_cols]\n",
    "no_zips = model_params.drop(zipcode_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:16.583226Z",
     "start_time": "2021-07-22T02:10:16.447227Z"
    }
   },
   "outputs": [],
   "source": [
    "## Generating list of index names for slicing\n",
    "\n",
    "zips_idx = only_zips.index\n",
    "no_zips_idx = no_zips.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:16.725226Z",
     "start_time": "2021-07-22T02:10:16.586226Z"
    }
   },
   "outputs": [],
   "source": [
    "## Formatting labels for visualizations\n",
    "\n",
    "no_zips.index = [i.title().replace('_',' ').replace('Sqft','Square Footage of')\\\n",
    "               .replace('Yr', 'Year').replace('Lat', 'Latitude')\\\n",
    "               .replace('Long','Longitude')\\\n",
    "                 .replace('Grade', 'Material Grade: ') for i in no_zips.index]\n",
    "\n",
    "only_zips.index = [i.replace('zipcode_', ' ') for i in only_zips.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:21:03.314762Z",
     "start_time": "2021-07-22T02:21:01.246763Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Plotting zipcodes visualization\n",
    "\n",
    "pf.plot_coefs(data = only_zips, kind = \"barh\", figsize=(10,30),\n",
    "           x_label = 'Price ($)', y_label = 'Zip Codes',\n",
    "           title= 'Zip Code Effect on Price');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T02:24:10.864645Z",
     "start_time": "2021-07-15T02:24:10.391507Z"
    }
   },
   "source": [
    "## Visualizing all parameters besides zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:19.291259Z",
     "start_time": "2021-07-22T02:10:18.683227Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Plotting all features besides zip codes\n",
    "pf.plot_coefs(data = no_zips, kind = \"bar\", x_label = 'Features Other Than Zip Code',\n",
    "           y_label = 'Price ($)', title= 'House Feature Effect on Price',\n",
    "          figsize = (15,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">As expected, the models demonstrate a very strong negative effect on price for most of the coefficients. The magnitude of the negative effects minimizes the visualization of the few positive coefficients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚿 **Instantiating Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I create two different pipelines for my actual modeling process, one that does not include a scaler and another that does.\n",
    ">\n",
    "> The purpose behind the two pipelines is to visualize the impact of scaling data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Scaled Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:19.417226Z",
     "start_time": "2021-07-22T02:10:19.294239Z"
    }
   },
   "outputs": [],
   "source": [
    "## Instantiating full pipeline with ColumnTransformer and LinearRegression\n",
    "reg_pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('regressor', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:19.711225Z",
     "start_time": "2021-07-22T02:10:19.419227Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Fitting pipeline to the training data\n",
    "reg_pipe.fit(X_train, y_train)\n",
    "\n",
    "## Evaluating model performance\n",
    "pf.eval_perf_total(reg_pipe, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The model performs very well on both the training and test data with $r^2$ scores pf .84 and .82, respectively. The increase in RMSE and decrease in $r^2$ for the second model indicates some overfitting of the model, however. \n",
    "\n",
    ">These results indicate the model explains 82% of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnP7OWpnsq2i"
   },
   "source": [
    "### Verifying Linear Regression Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:19.883227Z",
     "start_time": "2021-07-22T02:10:19.713226Z"
    }
   },
   "outputs": [],
   "source": [
    "## Generating predictions for the unscaled pipeline\n",
    "y_test_pred = reg_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:20.761258Z",
     "start_time": "2021-07-22T02:10:19.886228Z"
    },
    "id": "OFnElN0Rsq2i",
    "outputId": "ee26d375-8ed7-43ab-cabe-c1b9b3e9315b"
   },
   "outputs": [],
   "source": [
    "## Determining residuals\n",
    "residuals = (y_test - y_test_pred)\n",
    "\n",
    "## Plotting to test for normality\n",
    "sns.histplot(data=residuals);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:22.233229Z",
     "start_time": "2021-07-22T02:10:20.763226Z"
    },
    "id": "-XvKdUZ8sq2i",
    "outputId": "a5d0fd55-9b9b-416d-9c9a-a9cf108cade0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Checking the homoscedasticity of the new model\n",
    "sns.residplot(x=y_test, y=residuals, lowess=True, color=\"g\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:22.531290Z",
     "start_time": "2021-07-22T02:10:22.235229Z"
    }
   },
   "outputs": [],
   "source": [
    "sms.graphics.qqplot(data=residuals, fit=True, line = \"45\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The graphs above indicate that the model does not fully meet the assumptions of residual normality.\n",
    ">\n",
    "> Based on the the histogram and Q-Q plots, the model is not a fully normal distribution (skewed to the right due to outliers in price. Additionally, the residplot shows a slight cone form, violating the assumption of homoscedasticity.\n",
    ">\n",
    "> While this model's residual testing is not ideal, it is workable enough to use the model for now. In the future, I may perform outlier removal to clean up the data and address these issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Scaled Coefficients for Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **The first model is complete and I can now provide recommendations based off the results.** I will review the model's coefficients to provide my recommendations to my stakeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:22.659286Z",
     "start_time": "2021-07-22T02:10:22.533226Z"
    }
   },
   "outputs": [],
   "source": [
    "## Retrieving the model coefficients from the model\n",
    "reg_coefs = pf.get_model_coefs(reg_pipe, final_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:22.785259Z",
     "start_time": "2021-07-22T02:10:22.661226Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Filtering out zipcode-related coefficients and sorting in a descending order\n",
    "reg_coefs[no_zips_idx].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡 **Recommendations** - *Non-Scaled*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> **Based on these results,** I would make the following recommendations to a homeowner interested in renovating to ***increase*** the sell price of their home (*all changes in price assume no other changes to the house*):\n",
    ">\n",
    "> * **Add another bathroom** - Adding another bathroom would increase the price by \\\\$23,452.61.\n",
    ">\n",
    ">\n",
    "> * **Increase the above-ground square-footage of the house** -  the price increases by \\\\$153.15 for each additional square foot.\n",
    ">\n",
    ">    * Depending on other factors affecting cost (including, but not limited to, materials, labor, etc.), *this may be the most reasonable approach for homeowners.*\n",
    ">\n",
    ">    * If a homeowner puts an addition on their house, for example, the additional square footage may exceed the benefit of adding a bathroom (assuming the bathroom is not an addition to the house/does not increase ft$^2$).\n",
    ">\n",
    ">\n",
    "> * **Increase the square-footage of the basement** -  the price increases by \\\\$112.64 for each additional square foot.\n",
    ">    * This approach may be more expensive than increasing above-ground space due to costs of removing dirt and adding support to maintain the structural integrity of the foundation/support for the rest of the house.\n",
    ">\n",
    ">---\n",
    "> **Furthermore,** I would advise homeowners ***not*** to make the following changes that *decrease* the price (*all changes in price assume no other changes to the house*):\n",
    ">\n",
    "> * **Adding another floor** decreases price by \\\\$24,944.90 - quite a hit considering the potential construction costs of that extra level!\n",
    ">\n",
    ">\n",
    "> * **Building a bedroom** decreases price by \\\\$11,372.35 - assuming you don't add more square footage to the house, building an extra bedroom would take away from the pre-existing space - a home needs more rooms than just bedrooms!\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Visualizations for Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These next few visualizations show each selected feature's increase on price. I will use these in my presentation to homeowners. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:24.163227Z",
     "start_time": "2021-07-22T02:10:22.787242Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.regplot(data=df_dropped, x=\"bathrooms\", y='price', line_kws={\"color\": \"red\"})\n",
    "plt.suptitle('Impact of Number of Bathrooms on Price')\n",
    "plt.xlabel('Number of Bathrooms')\n",
    "plt.ylabel('Price ($)');\n",
    "# plt.savefig('bath_price.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:25.307228Z",
     "start_time": "2021-07-22T02:10:24.166227Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.regplot(data=df_dropped, x=\"sqft_above\", y='price', line_kws={\"color\": \"red\"})\n",
    "plt.suptitle('Impact of Above-Ground Ft^2 on Price')\n",
    "plt.xlabel('Above-Ground ft^2')\n",
    "plt.ylabel('Price ($)');\n",
    "# plt.savefig('abovesqft_price.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:26.650227Z",
     "start_time": "2021-07-22T02:10:25.310228Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.regplot(data=df_dropped, x=\"sqft_basement\", y='price', line_kws={\"color\": \"red\"})\n",
    "plt.suptitle('Impact of Basement Ft^2 on Price')\n",
    "plt.xlabel('Basement Ft^2')\n",
    "plt.ylabel('Price ($)');\n",
    "# plt.savefig('base_price.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following plots, I separate the zip code coefficients from the rest of the data for clarity's sake. **Please make note of the different scales for price on the x_axis.** The second graph has a larger scale, shrinking the bars slightly in comparison to the first graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:26.774255Z",
     "start_time": "2021-07-22T02:10:26.652225Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Generating lists of coefficient names for filtering\n",
    "\n",
    "zipcode_cols = [x for x in reg_coefs.index if x.startswith('zipcode')]\n",
    "\n",
    "only_zips = reg_coefs[zipcode_cols]\n",
    "no_zips = reg_coefs.drop(zipcode_cols)\n",
    "no_zips = no_zips.drop('intercept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:26.916267Z",
     "start_time": "2021-07-22T02:10:26.777256Z"
    }
   },
   "outputs": [],
   "source": [
    "## Generating list of index names for slicing\n",
    "\n",
    "zips_idx = only_zips.index\n",
    "no_zips_idx = no_zips.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:27.044227Z",
     "start_time": "2021-07-22T02:10:26.919230Z"
    }
   },
   "outputs": [],
   "source": [
    "## Formatting labels for visualizations\n",
    "\n",
    "no_zips.index = [i.title().replace('_',' ').replace('Sqft','Square Footage of')\\\n",
    "               .replace('Yr', 'Year').replace('Y_', 'Year').replace('Lat', 'Latitude')\\\n",
    "               .replace('Long','Longitude')\\\n",
    "                 .replace('Grade', 'Material Grade: ') for i in no_zips.index]\n",
    "\n",
    "only_zips.index = [i.replace('zipcode_', ' ') for i in only_zips.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:29.858226Z",
     "start_time": "2021-07-22T02:10:27.050228Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Generating two plots: one for zip codes, then another for all other features\n",
    "\n",
    "pf.plot_coefs(data = only_zips, kind = \"barh\", figsize=(20,25), x_label = 'Price ($)',\n",
    "           y_label = 'Zip Codes', title= 'Effects of Zip Codes on Price')\n",
    "\n",
    "# plt.savefig('reg_coef_zip.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "pf.plot_coefs(data = no_zips, kind = \"barh\", figsize=(15,25),\n",
    "              x_label = 'Price ($)',\n",
    "              y_label = 'Features', \n",
    "              title= 'Effects of Non-Zipcode Features on Price');\n",
    "\n",
    "# plt.savefig('reg_no_zip.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:29.997225Z",
     "start_time": "2021-07-22T02:10:29.861227Z"
    }
   },
   "outputs": [],
   "source": [
    "## Creating full pipeline with ColumnTransformer, StandardScaler and LinearRegression\n",
    "reg_pipe_scaled = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('scaler', StandardScaler()),\n",
    "                      ('regressor', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:30.373228Z",
     "start_time": "2021-07-22T02:10:29.999226Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Fittng pipeline to the training data\n",
    "reg_pipe_scaled.fit(X_train, y_train)\n",
    "\n",
    "## Ensuring same results as prior pipeline\n",
    "pf.eval_perf_total(reg_pipe_scaled, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled Coefficients for Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **The second model is complete and I can now provide updated recommendations based off the results.** As the data is now scaled based on the data's averages and standard deviations, the results are different than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:30.530227Z",
     "start_time": "2021-07-22T02:10:30.376229Z"
    }
   },
   "outputs": [],
   "source": [
    "## Pulling model coefficients for visualizations\n",
    "\n",
    "reg_pipe_scaled_coefs = pf.get_model_coefs(reg_pipe_scaled, final_cols)\n",
    "\n",
    "reg_scaled_zips = reg_pipe_scaled_coefs[zipcode_cols]\n",
    "\n",
    "reg_scaled_no_zips = reg_pipe_scaled_coefs[no_zips_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:30.655280Z",
     "start_time": "2021-07-22T02:10:30.533227Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reg_scaled_no_zips.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡 **Recommendations** - *Scaled*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> **Based on these results,** I stand by my earlier recommendations of increasing above-ground ft.$^2$, basement ft.$^2$, or adding another bathroom and avoiding adding additional floors or bedrooms.\n",
    ">\n",
    ">The results for this model are measured in units of standard deviation, making them harder to interpret and less presentation-friendly (i.e. to increase the price with above-ground square footage, you would need to add one unit of standard deviation's worth of square footage).\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Scaled Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of how these scaled variables changed, I visualize the results. **Please make note of the different scales for price on the x_axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:30.812224Z",
     "start_time": "2021-07-22T02:10:30.658228Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Generating lists of coefficient names for filtering\n",
    "\n",
    "zipcode_cols = [x for x in reg_pipe_scaled_coefs.index if \\\n",
    "                x.startswith('zipcode')]\n",
    "\n",
    "only_zips = reg_pipe_scaled_coefs[zipcode_cols]\n",
    "no_zips = reg_pipe_scaled_coefs.drop(zipcode_cols)\n",
    "no_zips = no_zips.drop('intercept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:30.924230Z",
     "start_time": "2021-07-22T02:10:30.814225Z"
    }
   },
   "outputs": [],
   "source": [
    "## Generating list of index names for slicing\n",
    "\n",
    "zips_idx = only_zips.index\n",
    "no_zips_idx = no_zips.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:31.050227Z",
     "start_time": "2021-07-22T02:10:30.927225Z"
    }
   },
   "outputs": [],
   "source": [
    "## Formatting labels for visualizations\n",
    "\n",
    "no_zips.index = [i.title().replace('_',' ').replace('Sqft','Square Footage: ')\\\n",
    "               .replace('Yr', 'Year').replace('Lat', 'Latitude')\\\n",
    "               .replace('Long','Longitude')\\\n",
    "                 .replace('Grade', 'Material Grade: ') for i in no_zips.index]\n",
    "\n",
    "only_zips.index = [i.replace('zipcode_', ' ') for i in only_zips.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:16:53.942143Z",
     "start_time": "2021-07-22T02:16:51.729144Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Plotting coefficients\n",
    "\n",
    "pf.plot_coefs(data = only_zips, kind = \"barh\", figsize=(15,35), \n",
    "              x_label = 'Price',y_label = 'Zip Codes', \n",
    "              title= 'Zip Code Effect on Price ($)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:19:19.088826Z",
     "start_time": "2021-07-22T02:19:18.461820Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pf.plot_coefs(data = no_zips, kind = \"barh\", figsize=(10,20), x_label = 'Price',\n",
    "              y_label = 'Features Other Than Zip Code', \n",
    "              title= 'Effects of House Features on Price ($)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 💡 **Final Recommendations** 💡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> **Based on my model's results,** I would make the following recommendations to a homeowner interested in renovating to ***increase*** the sell price of their home (*all changes in price assume no other changes to the house*):\n",
    ">\n",
    "> * **Add another bathroom** - Adding another bathroom would increase the price by \\\\$23,452.61.\n",
    ">\n",
    ">\n",
    "> * **Increase the above-ground square-footage of the house** -  the price increases by \\\\$153.15 for each additional square foot.\n",
    ">\n",
    ">\n",
    "> * **Increase the square-footage of the basement** -  the price increases by \\\\$112.64 for each additional square foot.\n",
    ">\n",
    ">---\n",
    "> **Furthermore,** I would advise homeowners ***not*** to make the following changes as they *decrease* the price (*all changes in price assume no other changes to the house*):\n",
    ">\n",
    "> * **Adding another floor** decreases price by \\\\$24,944.90 - quite a hit considering the potential construction costs of that extra level!\n",
    ">\n",
    ">\n",
    "> * **Building a bedroom** decreases price by \\\\$11,372.35 - assuming you don't add more square footage to the house, building an extra bedroom would take away from the pre-existing space - a home needs more rooms than just bedrooms!\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔮 **Creating Predictions on Holdout Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now that I finished my model, I will read in the new test data and generate my final predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:34.121231Z",
     "start_time": "2021-07-22T02:10:33.967255Z"
    }
   },
   "outputs": [],
   "source": [
    "df_xtest = pd.read_csv('bakeoff_data/Xtest.csv')\n",
    "df_xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:34.353225Z",
     "start_time": "2021-07-22T02:10:34.123233Z"
    }
   },
   "outputs": [],
   "source": [
    "pf.report_df(df_xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0RzFYbgcsq2F"
   },
   "source": [
    "# **🛠 Processing New Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:34.478230Z",
     "start_time": "2021-07-22T02:10:34.355226Z"
    }
   },
   "outputs": [],
   "source": [
    "df_xtest['sqft_basement'] = pd.to_numeric(df_xtest['sqft_basement'], errors='coerce')\n",
    "df_xtest['sqft_basement']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mpimDh2sq2F"
   },
   "source": [
    "## `'yrs_old_sold'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgTdOjJnsq2F"
   },
   "source": [
    "### Determine `'year_sold'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:35.059235Z",
     "start_time": "2021-07-22T02:10:34.481227Z"
    },
    "id": "ltoQKbEFsq2G",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Pull the year from the \"date\" column\n",
    "df_xtest['year_sold'] = pd.DatetimeIndex(df_xtest['date']).year\n",
    "\n",
    "## Review the values to ensure data integrity\n",
    "df_xtest['year_sold'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9dY6ryUsq2G"
   },
   "source": [
    "### Calculate `'yr_old_sold'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:35.198227Z",
     "start_time": "2021-07-22T02:10:35.063234Z"
    },
    "id": "EjI_PHB0sq2G",
    "outputId": "f8199020-11ed-4252-80af-ee86afb89a78",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Calculating the age of the house at the time of sale\n",
    "df_xtest['yr_old_sold'] = df_xtest['year_sold'] - df_xtest['yr_built']\n",
    "\n",
    "## Minimum age is -1 due to a house being sold before it was finished being built\n",
    "display(df_xtest['yr_old_sold'].value_counts().sort_index(), df_xtest['yr_old_sold'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gzl5f2Ktsq2H"
   },
   "source": [
    "## `'was_renovated'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:35.342230Z",
     "start_time": "2021-07-22T02:10:35.200226Z"
    },
    "id": "X7QoQoBLsq2I"
   },
   "outputs": [],
   "source": [
    "## Using the year that the home was renovated to deterine whether or not the home was renovated\n",
    "reno_y_n = np.where(df_xtest['yr_renovated']>0, 1, 0 )\n",
    "df_xtest = df_xtest.assign(was_renovated = reno_y_n)\n",
    "df_xtest.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:35.469230Z",
     "start_time": "2021-07-22T02:10:35.344226Z"
    },
    "id": "kltnwNfIsq2I",
    "outputId": "caaada13-58e0-4c08-cf62-7b8fbeedf911"
   },
   "outputs": [],
   "source": [
    "## Checking values\n",
    "df_xtest['was_renovated'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb2ISg5Xsq2I"
   },
   "source": [
    "## `\"yrs_since_reno\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:35.592229Z",
     "start_time": "2021-07-22T02:10:35.472230Z"
    }
   },
   "outputs": [],
   "source": [
    "## Ensuring there are no null values in the new feature and replacing any with zeroes\n",
    "\n",
    "df_xtest['yrs_since_reno'] = np.where((df_xtest['was_renovated']==1),\n",
    "                                (df_xtest['year_sold'] - df_xtest['yr_renovated']), 0)\n",
    "\n",
    "# display(df_xtest['yrs_since_reno'].describe(),df_xtest['yrs_since_reno'].value_counts(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:35.718228Z",
     "start_time": "2021-07-22T02:10:35.595228Z"
    }
   },
   "outputs": [],
   "source": [
    "## Reviewing stats for those houses that were renovated\n",
    "\n",
    "yrs_and_reno = df_xtest[df_xtest['yrs_since_reno'] > 0]\n",
    "yrs_and_reno['yrs_since_reno'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6TwLd00sq2J"
   },
   "source": [
    "## \"`has_bsmnt`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:35.893229Z",
     "start_time": "2021-07-22T02:10:35.720230Z"
    },
    "id": "lWHPc64-sq2J",
    "outputId": "1b48b91d-ebaf-4cdb-be5d-811fa8334a21",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Determining whether or not a house has a basement based on the square footage\n",
    "df_xtest['has_bsmnt'] = np.where(df_xtest['sqft_basement'] > 0, 1, 0)\n",
    "\n",
    "# Reviewing the results\n",
    "display(df_xtest['has_bsmnt'].describe(), df_xtest['has_bsmnt'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping for Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:36.032228Z",
     "start_time": "2021-07-22T02:10:35.898229Z"
    }
   },
   "outputs": [],
   "source": [
    "df_xtest.drop(['was_renovated', 'sqft_living','has_bsmnt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔮 **Generating Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:36.157228Z",
     "start_time": "2021-07-22T02:10:36.035229Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:36.298228Z",
     "start_time": "2021-07-22T02:10:36.159229Z"
    }
   },
   "outputs": [],
   "source": [
    "df_xtest = df_xtest[X_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:36.457228Z",
     "start_time": "2021-07-22T02:10:36.301228Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_predictions = reg_pipe.predict(df_xtest)\n",
    "final_predictions = pd.Series(final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T02:10:36.628228Z",
     "start_time": "2021-07-22T02:10:36.460227Z"
    }
   },
   "outputs": [],
   "source": [
    "# final_predictions.to_csv('mccartyb_phase2_predict.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "P2Pv2_wb.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python (learn-env-bmc)",
   "language": "python",
   "name": "learn-env-bmc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "757px",
    "left": "35px",
    "top": "110px",
    "width": "330.994px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
